{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "450cc6f6-1127-46b9-b8ac-328a60fdc9f3",
   "metadata": {},
   "source": [
    "#### This Project is all about Principal Component Analysis - A Dimensionality Reduction Technique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd86386-e271-479a-8771-9bfd8d6787a5",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "- The curse of Dimensionality.\n",
    "- Introduction of Principal Component Analysis.\n",
    "- Import Python Libraries\n",
    "- Import Dataset\n",
    "- EDA\n",
    "- Split data into training and test set\n",
    "- Feature Engineering\n",
    "- Feature Scaling\n",
    "- Logistic Regression model with all features\n",
    "- Logistic Regression with PCA\n",
    "- Select the right number of dimensions\n",
    "- Plot explained variance ratio with the number of dimensions\n",
    "- Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7fff80-b9c0-4614-80f9-3bd155d57581",
   "metadata": {},
   "source": [
    "### The Curse of Dimensionality\n",
    "Generally, real-world datasets contain thousands or millions of features to train for. This is a very time-consuming task, as it significantly slows down training. In such cases, it is very difficult to find a good solution. This problem is often referred to as the curse of Dimensionality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29050be6-f47c-4c6f-ad81-98f02a01a302",
   "metadata": {},
   "source": [
    "The Curse of Dimensionality refers to various phenomena that arise when we analyze and organize data in high-dimensional spaces that do not occur in low-dimensional settings. The problem is that when the dimensionality increases, the volume of space increases so fast that the available data becomes sparse. The sparsity is problematic for any method that requires statistical significance.\n",
    "\n",
    "In real-world problems. It is often possible to reduce the number of dimensions considerably. This process is called dimensionality reduction. It refers to the process of reducing the number of dimensions under consideration by obtaining a set of principal variables. It helps to speed up training and is also extremely useful for data visualization.\n",
    "\n",
    "The most popular dimensionality reduction technique is PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caa7c94-9bc6-47d2-ad0a-a2354cd8d36f",
   "metadata": {},
   "source": [
    "## Introduction to Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01646a57-ba8c-4d0f-9ab6-07e9a841ed02",
   "metadata": {},
   "source": [
    "Principal Component Analysis (PCA) is a Dimensionality reduction technique that can be used to reduce a large set of feature variables into a smaller set that still contains most of the variance in the large set.\n",
    "\n",
    "**Preserve the Variance**\n",
    "- PCA first identifies the hyperplane that lies closest to the data and then projects the data onto it. Before we can project the training set onto a lower-dimensional hyperplane. We need to select the right hyperplane. The projection can be done in such a way as to preserve the maximum variance. This is the idea behind PCA.\n",
    "\n",
    "**Principal Components**\n",
    "- PCA identifies the axes that account for the maximum amount of cumulative sum of variance in the training set. These are called Principal Components. PCA assumes that the dataset is centered around the origin. Scikit-Learn's PCA classes take care of centering the data automatically.\n",
    "\n",
    "**Projection down to Dimensions**\n",
    "- Once we have identified all the principal components, we can reduce the dimensionality of the dataset to dimensions by projecting it onto the hyperplane defined by the first principal components. This ensures that the projection will preserve as much variance as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a602037-3679-44fb-957f-22be6aefb1d6",
   "metadata": {},
   "source": [
    "# Import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32329db4-8aee-4b84-b4b4-f8f6e5ffdd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd33b8-fd5e-4f6c-8402-d4505f07cca4",
   "metadata": {},
   "source": [
    "### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7835d7ec-8217-4b81-88a0-7599905b08fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('adult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0001fd84-5927-4066-a946-ea814951d0a1",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74064ea-4ce1-47b1-8ad0-f57077f1cd33",
   "metadata": {},
   "source": [
    "### Check shape of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bf3ef925-1eef-46f2-b997-58975c43394c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 15)\n",
      "We can see that there are 32561 instances and 15 attributes in the datset\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print('We can see that there are 32561 instances and 15 attributes in the datset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e9753f-9e28-4d46-a285-0ef6bf1cbe9e",
   "metadata": {},
   "source": [
    "### Preview dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dc2f441b-d73f-48e6-845d-54e2d066a519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0   90         ?   77053       HS-grad              9        Widowed   \n",
       "1   82   Private  132870       HS-grad              9        Widowed   \n",
       "2   66         ?  186061  Some-college             10        Widowed   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family  White  Female             0   \n",
       "1    Exec-managerial  Not-in-family  White  Female             0   \n",
       "2                  ?      Unmarried  Black  Female             0   \n",
       "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
       "4     Prof-specialty      Own-child  White  Female             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356              40  United-States  <=50K  \n",
       "1          4356              18  United-States  <=50K  \n",
       "2          4356              40  United-States  <=50K  \n",
       "3          3900              40  United-States  <=50K  \n",
       "4          3900              40  United-States  <=50K  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00523f81-f0ef-45b7-a42e-4fda93bab39c",
   "metadata": {},
   "source": [
    "### View summary of dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00bf790e-dc80-4d78-89b1-24b0f66f8946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       32561 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education.num   32561 non-null  int64 \n",
      " 5   marital.status  32561 non-null  object\n",
      " 6   occupation      32561 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital.gain    32561 non-null  int64 \n",
      " 11  capital.loss    32561 non-null  int64 \n",
      " 12  hours.per.week  32561 non-null  int64 \n",
      " 13  native.country  32561 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aec156e-c32d-4354-a599-9578ee48ba22",
   "metadata": {},
   "source": [
    "Summary of the dataset shows that there are no missing values. But the preview shows that the dataset contains values coded as `?`. So, I will encode `?` as NaN values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9454d76-cf53-4dc4-b1d3-67fe0863e5ed",
   "metadata": {},
   "source": [
    "### Encode ? as NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2d53b8c-16bf-4281-9f09-f6c2a57320e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df == '?' ]= np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2840fb74-4a5c-41c9-8deb-2f3b9a6cc91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             32561 non-null  int64 \n",
      " 1   workclass       30725 non-null  object\n",
      " 2   fnlwgt          32561 non-null  int64 \n",
      " 3   education       32561 non-null  object\n",
      " 4   education.num   32561 non-null  int64 \n",
      " 5   marital.status  32561 non-null  object\n",
      " 6   occupation      30718 non-null  object\n",
      " 7   relationship    32561 non-null  object\n",
      " 8   race            32561 non-null  object\n",
      " 9   sex             32561 non-null  object\n",
      " 10  capital.gain    32561 non-null  int64 \n",
      " 11  capital.loss    32561 non-null  int64 \n",
      " 12  hours.per.week  32561 non-null  int64 \n",
      " 13  native.country  31978 non-null  object\n",
      " 14  income          32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd7dc0f-2132-482a-a4fa-547582c2cec1",
   "metadata": {},
   "source": [
    "Now, the summary shows that the variables - `workclass`, `occupation` and `native.country` contain missing values. All of these variables are categorical data type. So, I will impute the missing values with the most frequent value- the mode."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8d47b1-469c-4ffd-bac0-f94e6c04c9f8",
   "metadata": {},
   "source": [
    "### Impute missing values with mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "579252f6-b422-4e23-aaa0-d076a0d5b9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['workclass','occupation','native.country']:\n",
    "    df[col].fillna(df[col].mode()[0],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9172d99-af59-47d7-8579-6b33d2671a9a",
   "metadata": {},
   "source": [
    "### Check again for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c7ef068-baf0-4078-8b03-9a14ab6e9946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               0\n",
       "workclass         0\n",
       "fnlwgt            0\n",
       "education         0\n",
       "education.num     0\n",
       "marital.status    0\n",
       "occupation        0\n",
       "relationship      0\n",
       "race              0\n",
       "sex               0\n",
       "capital.gain      0\n",
       "capital.loss      0\n",
       "hours.per.week    0\n",
       "native.country    0\n",
       "income            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a00166a-a170-4d9f-84d3-0384fb1a2fe8",
   "metadata": {},
   "source": [
    "Now we can see that there are no missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "66451b5b-48ef-4909-a37a-4cd363ac40e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['income'],axis = 1)\n",
    "y = df['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "624c13eb-affb-448e-afb5-23d2b37e3e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>Private</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>Private</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0   90   Private   77053       HS-grad              9        Widowed   \n",
       "1   82   Private  132870       HS-grad              9        Widowed   \n",
       "2   66   Private  186061  Some-college             10        Widowed   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0     Prof-specialty  Not-in-family  White  Female             0   \n",
       "1    Exec-managerial  Not-in-family  White  Female             0   \n",
       "2     Prof-specialty      Unmarried  Black  Female             0   \n",
       "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
       "4     Prof-specialty      Own-child  White  Female             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country  \n",
       "0          4356              40  United-States  \n",
       "1          4356              18  United-States  \n",
       "2          4356              40  United-States  \n",
       "3          3900              40  United-States  \n",
       "4          3900              40  United-States  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "72389362-881f-447d-883f-a4842da84d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f0cb49-1a2c-40aa-b037-0da3e9db0bca",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    " Encode categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "37f2cbfe-6358-4aa2-ac31-2b58e2df1f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = ['workclass','education','marital.status','occupation','relationship','race','sex','native.country']\n",
    "for i in cat:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    X_train[i] = le.fit_transform(X_train[i])\n",
    "    X_test[i] = le.transform(X_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce6c66-9a14-4ab1-923f-c409c359f981",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70b6cc30-ed2f-43e8-8aee-294379112f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = pd.DataFrame(sc.fit_transform(X_train),columns=X.columns)\n",
    "X_test = pd.DataFrame(sc.transform(X_test),columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "07ddb2da-09d0-418b-a27d-b2807516543a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.101484</td>\n",
       "      <td>2.600478</td>\n",
       "      <td>-1.494279</td>\n",
       "      <td>-0.332263</td>\n",
       "      <td>1.133894</td>\n",
       "      <td>-0.402341</td>\n",
       "      <td>-0.782234</td>\n",
       "      <td>2.214196</td>\n",
       "      <td>0.39298</td>\n",
       "      <td>-1.430470</td>\n",
       "      <td>-0.145189</td>\n",
       "      <td>-0.217407</td>\n",
       "      <td>-1.662414</td>\n",
       "      <td>0.262317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028248</td>\n",
       "      <td>-1.884720</td>\n",
       "      <td>0.438778</td>\n",
       "      <td>0.184396</td>\n",
       "      <td>-0.423425</td>\n",
       "      <td>-0.402341</td>\n",
       "      <td>-0.026696</td>\n",
       "      <td>-0.899410</td>\n",
       "      <td>0.39298</td>\n",
       "      <td>0.699071</td>\n",
       "      <td>-0.145189</td>\n",
       "      <td>-0.217407</td>\n",
       "      <td>-0.200753</td>\n",
       "      <td>0.262317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.247956</td>\n",
       "      <td>-0.090641</td>\n",
       "      <td>0.045292</td>\n",
       "      <td>1.217715</td>\n",
       "      <td>-0.034095</td>\n",
       "      <td>0.926666</td>\n",
       "      <td>-0.782234</td>\n",
       "      <td>-0.276689</td>\n",
       "      <td>0.39298</td>\n",
       "      <td>-1.430470</td>\n",
       "      <td>-0.145189</td>\n",
       "      <td>-0.217407</td>\n",
       "      <td>-0.038346</td>\n",
       "      <td>0.262317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.850587</td>\n",
       "      <td>-1.884720</td>\n",
       "      <td>0.793152</td>\n",
       "      <td>0.184396</td>\n",
       "      <td>-0.423425</td>\n",
       "      <td>0.926666</td>\n",
       "      <td>-0.530388</td>\n",
       "      <td>0.968753</td>\n",
       "      <td>0.39298</td>\n",
       "      <td>0.699071</td>\n",
       "      <td>-0.145189</td>\n",
       "      <td>-0.217407</td>\n",
       "      <td>-0.038346</td>\n",
       "      <td>0.262317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.044989</td>\n",
       "      <td>-2.781760</td>\n",
       "      <td>-0.853275</td>\n",
       "      <td>0.442726</td>\n",
       "      <td>1.523223</td>\n",
       "      <td>-0.402341</td>\n",
       "      <td>-0.782234</td>\n",
       "      <td>-0.899410</td>\n",
       "      <td>0.39298</td>\n",
       "      <td>0.699071</td>\n",
       "      <td>-0.145189</td>\n",
       "      <td>-0.217407</td>\n",
       "      <td>-0.038346</td>\n",
       "      <td>0.262317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass    fnlwgt  education  education.num  marital.status  \\\n",
       "0  0.101484   2.600478 -1.494279  -0.332263       1.133894       -0.402341   \n",
       "1  0.028248  -1.884720  0.438778   0.184396      -0.423425       -0.402341   \n",
       "2  0.247956  -0.090641  0.045292   1.217715      -0.034095        0.926666   \n",
       "3 -0.850587  -1.884720  0.793152   0.184396      -0.423425        0.926666   \n",
       "4 -0.044989  -2.781760 -0.853275   0.442726       1.523223       -0.402341   \n",
       "\n",
       "   occupation  relationship     race       sex  capital.gain  capital.loss  \\\n",
       "0   -0.782234      2.214196  0.39298 -1.430470     -0.145189     -0.217407   \n",
       "1   -0.026696     -0.899410  0.39298  0.699071     -0.145189     -0.217407   \n",
       "2   -0.782234     -0.276689  0.39298 -1.430470     -0.145189     -0.217407   \n",
       "3   -0.530388      0.968753  0.39298  0.699071     -0.145189     -0.217407   \n",
       "4   -0.782234     -0.899410  0.39298  0.699071     -0.145189     -0.217407   \n",
       "\n",
       "   hours.per.week  native.country  \n",
       "0       -1.662414        0.262317  \n",
       "1       -0.200753        0.262317  \n",
       "2       -0.038346        0.262317  \n",
       "3       -0.038346        0.262317  \n",
       "4       -0.038346        0.262317  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0e7738-429b-4bcc-8eb1-92c1a5160948",
   "metadata": {},
   "source": [
    "### Logistic Regression with all features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1b7d2e35-73fa-496d-9eb9-930645787e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy score with all features:0.8218\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Logistic Regression accuracy score with all features:{0:0.4f}'.format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284eba40-20b8-45de-919a-212fc06b42fa",
   "metadata": {},
   "source": [
    "### PCA Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cbccb58b-81de-4b28-a505-eb6a0e51d77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14757168, 0.10182915, 0.08147199, 0.07880174, 0.07463545,\n",
       "       0.07274281, 0.07009602, 0.06750902, 0.0647268 , 0.06131155,\n",
       "       0.06084207, 0.04839584, 0.04265038, 0.02741548])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05cf43a-0131-43a8-8785-7f3fbfe29cfb",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "- We can see that approximately 97.25% of variance is explained by the first 13 variables. \n",
    "- Only 2.75% of variance is explained by the last variable. So, we can assume that it carries little information. \n",
    "- So, I will drop it, train the model again and calculate the accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade07b81-6c18-4798-a2cc-3e57a71439f5",
   "metadata": {},
   "source": [
    "### Logistic Regression with first 13 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c7fac45e-4fac-4916-b011-2cdfae491e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy score with all features:0.8213\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['income','native.country'],axis=1)\n",
    "y = df['income']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "\n",
    "cat = ['workclass','education','marital.status','occupation','relationship','race','sex']\n",
    "for i in cat:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    X_train[i] = le.fit_transform(X_train[i])\n",
    "    X_test[i] = le.transform(X_test[i])\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = pd.DataFrame(sc.fit_transform(X_train),columns=X.columns)\n",
    "X_test = pd.DataFrame(sc.transform(X_test),columns=X.columns)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Logistic Regression accuracy score with all features:{0:0.4f}'.format(accuracy_score(y_test,y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3008513e-12c0-4f83-adf4-b8f14322dfdc",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "- We can see that accuracy has been decreased from 0.8218 to 0.8213 after dropping the last feature.\n",
    "- Now, if I take the last two features combined, then we can see that approximately 7% of variance is explained by them.\n",
    "- I will drop them, train the model again and calculate the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f2acc1-031a-4293-b1bd-3ae23d1f5a70",
   "metadata": {},
   "source": [
    "### Logistic Regression with first 12 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba717173-d517-4e18-a5ef-8d869986399c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy score with all features:0.8227\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['income','native.country','hours.per.week'],axis=1)\n",
    "y = df['income']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "\n",
    "cat = ['workclass','education','marital.status','occupation','relationship','race','sex']\n",
    "for i in cat:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    X_train[i] = le.fit_transform(X_train[i])\n",
    "    X_test[i] = le.transform(X_test[i])\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = pd.DataFrame(sc.fit_transform(X_train),columns=X.columns)\n",
    "X_test = pd.DataFrame(sc.transform(X_test),columns=X.columns)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Logistic Regression accuracy score with all features:{0:0.4f}'.format(accuracy_score(y_test,y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63efa5ad-9a72-403d-b5af-9ad46acefc36",
   "metadata": {},
   "source": [
    "### Comment\n",
    "- Now, it can be seen that the accuracy has been increased to 0.8227, if the model is trained with 12 features.\n",
    "- Lastly, I will take the last three features combined. Approximately 11.83% of variance is explained by them.\n",
    "- I will repeat the process, drop these features, train the model again and calculate the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3be926-6ff4-42c0-a21d-ab7c4fad398c",
   "metadata": {},
   "source": [
    "### Logistic Regression with first 12 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d2e3b113-687b-4409-8b52-9e6ae4bfbb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy score with all features:0.8186\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['income','native.country','hours.per.week','capital.loss'],axis=1)\n",
    "y = df['income']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "\n",
    "cat = ['workclass','education','marital.status','occupation','relationship','race','sex']\n",
    "for i in cat:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    X_train[i] = le.fit_transform(X_train[i])\n",
    "    X_test[i] = le.transform(X_test[i])\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = pd.DataFrame(sc.fit_transform(X_train),columns=X.columns)\n",
    "X_test = pd.DataFrame(sc.transform(X_test),columns=X.columns)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print('Logistic Regression accuracy score with all features:{0:0.4f}'.format(accuracy_score(y_test,y_pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392df380-d1d6-4560-9771-276429ab30ff",
   "metadata": {},
   "source": [
    "### Comment\n",
    "- We can see that accuracy has significantly decreased to 0.8187 if I drop the last three features.\n",
    "- Our aim is to maximize the accuracy. We get maximum accuracy with the first 12 features and the accuracy is 0.8227."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8cabd6-f1fb-4bb7-95af-4659b7071eba",
   "metadata": {},
   "source": [
    "## Select right number of dimensions\n",
    "\n",
    "- The above process works well if the number of dimensions are small.\n",
    "\n",
    "- But, it is quite cumbersome if we have large number of dimensions.\n",
    "\n",
    "- In that case, a better approach is to compute the number of dimensions that can explain significantly large portion of the variance.\n",
    "\n",
    "- The following code computes PCA without reducing dimensionality, then computes the minimum number of dimensions required to preserve 90% of the training set variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ea7930da-fe8b-45a0-ac3d-8e52816f6f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of dimensions required to preserve 90% of variance is 12\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['income'],axis = 1)\n",
    "y = df['income']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "\n",
    "cat = ['workclass','education','marital.status','occupation','relationship','race', 'sex','native.country']\n",
    "for i in cat:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    X_train[i] = le.fit_transform(X_train[i])\n",
    "    X_test[i] = le.transform(X_test[i])\n",
    "\n",
    "X_train = pd.DataFrame(sc.fit_transform(X_train),columns = X.columns)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "dim = np.argmax(cumsum >= 0.90) + 1\n",
    "print('The number of dimensions required to preserve 90% of variance is',dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c238354-9252-4c02-8026-ffbfb29f07d1",
   "metadata": {},
   "source": [
    "### Comment\n",
    "\n",
    "- With the required number of dimensions found, we can then set number of dimensions to `dim` and run PCA again.\n",
    "- With the number of dimensions set to `dim`, we can then calculate the required accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b16f870-6a7a-4c2c-8821-1ca7eee361ed",
   "metadata": {},
   "source": [
    "## Plot explained variance ratio with number of dimensions\n",
    "\n",
    "- An alternative option is to plot the explained variance as a function of the number of dimensions.\n",
    "- In the plot, we should look for an elbow where the explained variance stops growing fast.\n",
    "- This can be thought of as the intrinsic dimensionality of the dataset.\n",
    "- Now, I will plot cumulative explained variance ratio with number of components to show how variance ratio varies with number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bd5188d4-c0e0-445a-9aae-c57b09925123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiEAAAFzCAYAAADoudnmAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUxRJREFUeJzt3XdcE/fjBvAnYW9li2zBASgIqOBu3bPa4ayjtlpbrbNabeusdbW12jrxZ/VrW1dbd3FQtYpbGaKoKMqSIYIa9kru9weVlqKWQMIBed6vF6+XuSSXhxOSh8/dfU4iCIIAIiIiohomFTsAERERaSaWECIiIhIFSwgRERGJgiWEiIiIRMESQkRERKJgCSEiIiJRsIQQERGRKFhCiIiISBTaYgeoaQqFAikpKTAxMYFEIhE7DhERUZ0hCAKys7NhZ2cHqbT64xgaV0JSUlLg4OAgdgwiIqI6KykpCfb29tVej8aVEBMTEwClG9DU1FTkNERERHVHVlYWHBwcyj5Lq0vjSsizXTCmpqYsIURERFWgqsMZeGAqERERiYIlhIiIiETBEkJERESiYAkhIiIiUbCEEBERkShYQoiIiEgULCFEREQkClFLyJkzZzBgwADY2dlBIpFg//79//mc06dPw8/PD/r6+nB1dcXGjRvVH5SIiIhUTtQSkpubC29vb6xdu7ZSj4+Li0Pfvn3RqVMnRERE4NNPP8WUKVPw22+/qTkpERERqZqoM6b26dMHffr0qfTjN27cCEdHR6xevRoA0KJFC1y9ehVff/013njjDTWlJCIiEpcgCLjzMAfnYjMwpr0ztKT14wKsdWra9gsXLqBnz57llvXq1QtbtmxBcXExdHR0KjynsLAQhYWFZbezsrLUnpOIiKi60rMLcC42A6F3M3D2bgbSs0s/y/ycGsLboYG44VSkTpWQtLQ02NjYlFtmY2ODkpISZGRkoFGjRhWes2zZMixatKimIhIREVVJQbEcl+MeI/TuI4TezcDttOxy9+vrSNHOxQIKQRApoerVqRICVLxojvDXf8aLLqYzd+5czJgxo+z2sysAEhERiUmhEHAzNQtnYzMQevcRrsQ/QVGJoux+iQTwsjNDR3dLdHK3hJ9TQ+hpa4mYWPXqVAmxtbVFWlpauWXp6enQ1taGhYXFc5+jp6cHPT29mohHRET0Uqmy/LLdK+diM5CZW1Tufjsz/b9KhxU6uFnC3EhXpKQ1o06VkMDAQBw6dKjcsuPHj8Pf3/+5x4MQERGJKbewBJfiMhF6t/TYjtj0nHL3G+lqIbCJBTq6WaJTUyu4Whq9cGS/PhK1hOTk5CA2NrbsdlxcHCIjI2Fubg5HR0fMnTsXycnJ2L59OwBg4sSJWLt2LWbMmIHx48fjwoUL2LJlC3bu3CnWt0BERFRGrhBwI1lWdlxHeOITFMv/PoZDKgFa2TdAp79GO1o7NoCOlubOGypqCbl69SpeeeWVstvPjt0YM2YMtm3bhtTUVCQmJpbd7+LiguDgYEyfPh3r1q2DnZ0dvvvuO56eS0REokl6nFd2XMe52EzI8ovL3e9gboBO7lbo5GaJ9k0sYWbIkftnJIJQjw6zrYSsrCyYmZlBJpPB1NRU7DhERFTHZBcU48K90l0sZ2MzEJeRW+5+E31ttG9iUVo83C3hZGEkUlLVU/VnaJ06JoSIiEgMN5Jl+OPWQ4TezUBk0lPIFX///a4llaC1QwN0crdCR3dLeNubQVuDd7EogyWEiIjoOQpL5Ai+nor/nU9AZNLTcve5WhqVncUS4GoOE33uYqkKlhAiIqJ/SHmaj58vJWDX5aSyU2h1taTo1sIaXZqWjnbYNzQUOWX9wBJCREQaTxAEXLifie3nExBy62HZ7pZGZvp4O8AJQ9s4wNKYc06pGksIERFprNzCEuyNSMb28/G4+485PAJdLTCmvRO6t7Dh8R1qxBJCREQa596jHPx4IQG/hT1AdmEJAMBQVwuv+zbG6EBnNLUxETmhZmAJISIijSBXCDh1Ox3/uxCP0LsZZctdLI0wOtAJb/jZw5QHmNYolhAiIqrXnuQWYc/VJPx4MQEPnuQDKL04XLfm1hgd6IyObpaQSjVnqvTahCWEiIjqpRvJMmy/EI8DkSko/OvqtGYGOhjWxgFvBzjBwZxnuIiNJYSIiOqNohIFjtxIxfYLCQhLeFK23KORKca2d8YAbzsY6GqJmJD+iSWEiIjqvDRZAXZcTsSOS4nIyCkEAGhLJejbshHGtHeCr2NDjbo6bV3BEkJERHWSIAi4HPcY2y8k4Gh0WtncHtYmehjZzgnD2zrA2lRf5JT0MiwhRERUp+QVlWB/RAq2X4jH7bTssuVtnc0xur0TennaQodze9QJLCFERFQnxGfk4seLCdhzNQnZBaVze+jrSDG4dWOMCnCGhx2vjF7XsIQQEVGtJQgC/rzzCP87H48/Yx6VLXc0N8ToQCe85ecAM0PO7VFXsYQQEVGtI1cICL6einWnYsvtcunazApjAp3RpakV5/aoB1hCiIio1igqUWB/RDI2nL6HuIxcAICRrhaGtnHE6EAnOFsaiZyQVIklhIiIRJdfJMfuK4kIOnMfKbICAEADQx28094FY9o7oYGhrsgJSR1YQoiISDTZBcX48WICtoTGITO3CABgZaKHCZ1cMaKdI4z0+DFVn/F/l4iIatzj3CJsPReHbefjy850sW9ogIldmuBNP3vo63BWU03AEkJERDUmTVaAzaH3seNSIvKL5QAAN2tjfNi1CQZ423F+Dw3DEkJERGqXmJmHDafv4bewByiSl15MzquxKSZ1dUMvT1ue6aKhWEKIiEht7jzMxvpTsTh4LQV/zaqOts7m+PCVJujS1IrXc9FwLCFERKRyUQ+eYt2pWByLfli2rEtTK0x6xQ1tXcxFTEa1CUsIERGphCAIuBT3GOtOxSL0bgYAQCIBenva4sOubmhpbyZyQqptWEKIiKhaBEHAnzGPsO5ULK4mPAEAaEkleM3HDh92bQI3axORE1JtVeUSEhsbi3v37qFz584wMDCAIAjct0dEpEHkCgFHb6Rh3alY3EzNAgDoaksxxN8e73duAgdzQ5ETUm2ndAnJzMzE0KFDcfLkSUgkEty9exeurq5477330KBBA3zzzTfqyElERLVEsVyBA5EpWP9nLO4/Kp1a3VBXC28HOOG9ji6wNtUXOSHVFUqXkOnTp0NbWxuJiYlo0aJF2fKhQ4di+vTpLCFERPVUQbEcv1xNwsbT95H8NB8AYGagg7HtnTG2vTMaGnFqdVKO0iXk+PHjOHbsGOzt7cstd3d3R0JCgsqCERFR7ZBTWIKfLibg/0LjkJFTCACwNNbD+E4uGBngBGNOrU5VpPRPTm5uLgwNK+7ny8jIgJ6enkpCERGR+LILivF/oaVTq8vyiwEAjRsYYGIXV7zl78Cp1analC4hnTt3xvbt2/HFF18AACQSCRQKBb766iu88sorKg9IREQ1SxAEHIhMwZfBt/Aou3Tkw9XKCB92dcNrPpxanVRH6RLy1VdfoWvXrrh69SqKioowe/ZsREdH4/Hjxzh37pw6MhIRUQ2JScvGvAM3cDnuMQDA1dIIM3s2Q28vW2hxanVSMaVLiIeHB6KiorBhwwZoaWkhNzcXr7/+OiZNmoRGjRqpIyMREalZdkEx1vxxF1vPx0OuEKCvI8VHr7rjvU4u0NPmbhdSD4kgCILYIWpSVlYWzMzMIJPJYGpqKnYcIiJRCYKAg9dS8OXvt5D+166XXp42mNffA/YNOc8Hlafqz1ClR0K2bt0KY2NjvPXWW+WW//LLL8jLy8OYMWOqHYqIiNTv7sNszD8QjQv3MwEAzhaGWDDQE680sxY5GWkKpY8uWr58OSwtLSsst7a2xtKlS1USioiI1CensARLg2+hz5pQXLifCT1tKWb2aIqj0zqzgFCNUnokJCEhAS4uLhWWOzk5ITExUSWhiIhI9QRBwOGoVHz5+y2kZRUAAHp42GB+fw9OsU6iULqEWFtbIyoqCs7OzuWWX7t2DRYWFqrKRUREKhSbnoMFB2/gXGzprhdHc0MsHOiBV5vbiJyMNJnSJWTYsGGYMmUKTExM0LlzZwDA6dOnMXXqVAwbNkzlAYmIqOpyC0vw/clYbDl7H8VyAXraUnzY1Q3vd3HlZGMkOqVLyJIlS5CQkIBu3bpBW7v06QqFAqNHj+YxIUREtYQgCDhyIw1fHL6JVFnprpfuLawxv78nHC2464Vqhyqfonvnzh1cu3YNBgYGaNmyJZycnFSdTS14ii4R1Xf3HuVg4cFohN7NAAA4mBtgQX9PdPfgrheqHtFP0X2madOmaNq0abUDEBGRauQVlWDtyVhsDi3d9aKrLcXELk3wYdcm3PVCtZLSJUQul2Pbtm04ceIE0tPToVAoyt1/8uRJlYUjIqL/JggCjkWnYfGhm0j5a9fLK82ssHCgJ5wsjEROR/RiSpeQqVOnYtu2bejXrx+8vLwgkfBaAkREYonLyMWCg9E4c+cRgNKr3C4Y4IEeHjZ8f6ZaT+kSsmvXLuzZswd9+/ZVRx4iIqqE/CI51p2KRdCZ+yiSK6CrJcX7XVzxYVc3GOhy1wvVDUqXEF1dXbi5uakjCxER/QdBEHD85kMsPnQTyU/zAQCdm1ph0UBPuFhy1wvVLUqXkJkzZ2LNmjVYu3Yth/qIiGpQfEYuFh6Kxp8xf+96mdffA708ueuF6ialS8jZs2dx6tQpHDlyBJ6entDR0Sl3/969e1UWjoiISne9bPgzFhtPl+560dGSYEJnV0x6xQ2GulU+yZFIdEr/9DZo0ACDBw9WRxYiIvqXkJsPsehQNB48Kd310sndEosGesLVyljkZETVp3QJ2bp1qzpyEBHRPyRm5mHRoWicuJ0OAGhkpo/5/T3Q28uWu16o3uA4HhFRLVJQLMem0/ex7s9YFJWU7np5r5MrJr/iBiM9vmVT/VKln+hff/0Ve/bsQWJiIoqKisrdFx4erpJgRESa5s+YdCw4GI2EzDwAQPsmFlj8mhfcrLnrheonqbJP+O677/DOO+/A2toaERERaNu2LSwsLHD//n306dNHHRmJiOq1lKf5mPhjGMZuvYKEzDxYm+jh++Gt8fN77VhAqF5TuoSsX78eQUFBWLt2LXR1dTF79myEhIRgypQpkMlkSgdYv349XFxcoK+vDz8/P4SGhr708T///DO8vb1haGiIRo0a4Z133kFmZqbSr0tEJLaiEgU2nr6H7qtO42h0GrSkErzb0QUnZnbBAG87HvtB9Z7SJSQxMRHt27cHABgYGCA7OxsAMGrUKOzcuVOpde3evRvTpk3DZ599hoiICHTq1Al9+vRBYmLicx9/9uxZjB49Gu+++y6io6Pxyy+/4MqVK3jvvfeU/TaIiER14V4m+n4XiuVHbiOvSI42zg1x+KOOmNffAyb6Ov+9AqJ6QOkSYmtrWzby4OTkhIsXLwIA4uLiIAiCUutatWoV3n33Xbz33nto0aIFVq9eDQcHB2zYsOG5j7948SKcnZ0xZcoUuLi4oGPHjnj//fdx9epVZb8NIiJRpGcVYOquCAzffBGx6TmwMNLF1295Y8/7gWjRqPqXRieqS5QuIa+++ioOHToEAHj33Xcxffp09OjRA0OHDlVq/pCioiKEhYWhZ8+e5Zb37NkT58+ff+5z2rdvjwcPHiA4OBiCIODhw4f49ddf0a9fvxe+TmFhIbKyssp9ERHVtBK5AlvPxaHbN6dxIDIFEgnwdoAjTs7sijf97LnrhTSS0mfHBAUFQaFQAAAmTpwIc3NznD17FgMGDMDEiRMrvZ6MjAzI5XLY2NiUW25jY4O0tLTnPqd9+/b4+eefMXToUBQUFKCkpAQDBw7E999//8LXWbZsGRYtWlTpXEREqhaW8ATz9t/AzdTSP4K87c3wxSAvtLJvIG4wIpEpXUKkUimk0r8HUIYMGYIhQ4ZUOcC/278gCC/8i+DmzZuYMmUK5s+fj169eiE1NRWzZs3CxIkTsWXLluc+Z+7cuZgxY0bZ7aysLDg4OFQ5LxFRZT3OLcKKI7ex+2oSAMDMQAezezfDsDaO0JJy5IOoUiUkKioKXl5ekEqliIqKeuljW7VqVakXtrS0hJaWVoVRj/T09AqjI88sW7YMHTp0wKxZs8pey8jICJ06dcKSJUvQqFGjCs/R09ODnp5epTIREamCQiFg15UkrDx2G0/zigEAb/nZY06f5rAw5vsR0TOVKiE+Pj5IS0uDtbU1fHx8IJFInnsQqkQigVwur9QL6+rqws/PDyEhIeWOJQkJCcFrr7323Ofk5eVBW7t8ZC0tLQBQ+qBYIiJ1uP5Ahs8P3MC1pKcAgOa2JlgyyAv+zubiBiOqhSpVQuLi4mBlZVX2b1WZMWMGRo0aBX9/fwQGBiIoKAiJiYllx5bMnTsXycnJ2L59OwBgwIABGD9+PDZs2FC2O2batGlo27Yt7OzsVJaLiEhZsvxifHM8Bj9eTIAgAMZ62pjRoylGBzpBW0vpcwCINEKlSoiTkxMAoLi4GAsXLsS8efPg6upa7RcfOnQoMjMzsXjxYqSmpsLLywvBwcFlr5eamlpuzpCxY8ciOzsba9euxcyZM9GgQQO8+uqrWLFiRbWzEBFVhSAI2BuejGVHbiEjp/QyFgO97fBZvxawMdUXOR1R7SYRlNyP0aBBA4SHh6ukhIghKysLZmZmkMlkMDXlOflEVHUxadmYd+AGLsc9BgA0sTLCF695ob2bpcjJiNRD1Z+hSp8dM3jwYOzfv7/cGSdERJokp7AEa/64gx/OxUOuEGCgo4Up3dzxbkcX6Gpz1wtRZSldQtzc3PDFF1/g/Pnz8PPzg5GRUbn7p0yZorJwRES1iSAI+P16KpYcvoW0rAIAQC9PG8wf4InGDQxETkdU9yi9O8bFxeXFK5NIcP/+/WqHUifujiGiqrj/KAcLDkYj9G4GAMDJwhALB3rilWbWIicjqjmi745R5dkxRES1XX6RHOtOxSLozH0UyRXQ1Zbiw65NMLFLE+jraIkdj6hOU7qEEBFpij9uPsTCQ9F48CQfANC1mRUWDfSEk4XRfzyTiCqjSiXkwYMHOHjwIBITE1FUVFTuvlWrVqkkGBGRWJIe52HRoWj8cSsdAGBnpo/5AzzRy9OGF5ojUiGlS8iJEycwcOBAuLi4ICYmBl5eXoiPj4cgCPD19VVHRiKiGlEiV2Db+Xh8c/wO8ovl0NGS4L1OrvjoVTcY6nLgmEjVlP6tmjt3LmbOnInFixfDxMQEv/32G6ytrTFy5Ej07t1bHRmJiNTuZkoW5uyNQtQDGQAgwNUcSwZ5wc3aRORkRPWX0iXk1q1b2LlzZ+mTtbWRn58PY2NjLF68GK+99ho++OADlYckIlKXgmI5vjtxF5vO3IdcIcBUXxuf9WuBIf4O3PVCpGZKlxAjIyMUFhYCAOzs7HDv3j14enoCADIyMlSbjohIjS7cy8Sn+64jLiMXANCvZSMsGOgBaxNOt05UE5QuIQEBATh37hw8PDzQr18/zJw5E9evX8fevXsREBCgjoxERColyyvGsiO3sOtKEgDAxlQPX7zmhZ6etiInI9IsSpeQVatWIScnBwCwcOFC5OTkYPfu3XBzc8O3336r8oBERKoiCAKO3kjD/IPReJRdOqL7doAjZvduDlN9HZHTEWkepWdMres4YyqRZkqTFWD+gRs4fvMhgNKLzS1/oxXaOJuLnIyo7lD1Z6jSV1p65513cOLECWhYdyGiOkqhEPDTxQT0WHUax28+hI6WBFNedcPvUzqxgBCJTOndMZmZmejXrx8sLCwwbNgwjBo1Cj4+PmqIRkRUPbHpOZi7NwpX4p8AAHwcGmDFG63QzJan3RLVBlXaHfP06VPs2bMHO3bsQGhoKJo1a4a3334bI0aMgLOzsxpiqg53xxDVf0UlCmw6fQ/fn4xFkVwBQ10tzO7VDKMCnaEl5Wm3RFWl6s/Qah8T8uDBA+zcuRM//PAD7t69i5KSkmqHUieWEKL6LSLxCeb8dh0xD7MBlF7vZckgL9g3NBQ5GVHdJ/pVdP+puLgYV69exaVLlxAfHw8bG5tqByIiqorcwhJ8dSwG/7sQD0EAzI10sWCABwZ623HSMaJaqkol5NSpU9ixYwd+++03yOVyvP766zh06BBeffVVVecjIvpPp2LS8fm+G0h+Wnq129d9G+Pzfh4wN9IVORkRvYzSJcTe3h6ZmZno1asXNm3ahAEDBkBfn7MLElHNy8wpxOLDN3EgMgUAYN/QAEsHt0TnplYiJyOiylC6hMyfPx9vvfUWGjZsqI48RET/SRAE7ItIxheHb+JJXjGkEuDdji6Y3qMpr3ZLVIco/ds6YcIEdeQgIqqUpMd5+HTfdYTeLb1WVYtGpljxRku0sm8gbjAiUhr/ZCCiOkGuELD1XBy+OX4H+cVy6GpLMa27O8Z3coWOltLzLhJRLcASQkS13s2ULMzdG4VrD2QAgABXcyx7vRVcLI1ETkZE1cESQkS1VkGxHN+duIugM/dRohBgoq+Nz/u1wBB/B552S1QPsIQQUa108X4m5u69jriMXABA35a2WDjAE9amPBuPqL6oVAk5ePBgpVc4cODAKochIpLlF2P5kVvYeTkJAGBjqofFr3mhl6etyMmISNUqVUIGDRpU7rZEIil3Fd1/DovK5XLVJCMijfPHzYf4dN91pGcXAgBGtnPEJ32aw1RfR+RkRKQOlTqkXKFQlH0dP34cPj4+OHLkCJ4+fQqZTIbg4GD4+vri6NGj6s5LRPWQLK8YM3ZH4r3tV5GeXQhXKyPseT8QXw5uyQJCVI8pfUzItGnTsHHjRnTs2LFsWa9evWBoaIgJEybg1q1bKg1IRPXbP0c/pBJgfCdXTO/RFPo6WmJHIyI1U7qE3Lt3D2ZmZhWWm5mZIT4+XhWZiEgDyPKKsehwNPaGJwMAXK2M8PVb3vB15GzMRJpC6Rl+2rRpg2nTpiE1NbVsWVpaGmbOnIm2bduqNBwR1U8nbj1Ej29PY294MqQSYEJnVwRP6cQCQqRhlB4J+eGHHzB48GA4OTnB0dERAJCYmIimTZti//79qs5HRPVIhdEPSyN89ZY3/JxYPog0kdIlxM3NDVFRUQgJCcHt27chCAI8PDzQvXt3Th5ERC908vZDzN17HQ+zCiH569iPGTz2g0ijSYR/nmurpIKCAujp6dWp8pGVlQUzMzPIZDKYmpqKHYeo3pPlF2PxoZv4LfwBAI5+ENVlqv4MVfqYEIVCgS+++AKNGzeGsbEx4uLiAADz5s3Dli1bqh2IiOqPU7fT0fPb0/gt/MFfox8uCJ7aiQWEiABUoYQsWbIE27Ztw8qVK6Grq1u2vGXLlvi///s/lYYjorpJll+Mj3+5hne2XcHDrEK4Whrh14mB+KyfB3e/EFEZpUvI9u3bERQUhJEjR0JL6+83k1atWuH27dsqDUdEdc+p2+no9e0Z/BpWOvrxXsdnox/mYkcjolpG6QNTk5OT4ebmVmG5QqFAcXGxSkIRUd0jyy/GF4dv4tew0mM/XCyN8NWbreDvzPJBRM+ndAnx9PREaGgonJycyi3/5Zdf0Lp1a5UFI6K641RMOub+dh1pWQWQSIBxHVzwcc9mMNDlrhciejGlS8iCBQswatQoJCcnQ6FQYO/evYiJicH27dtx+PBhdWQkolpKll+MJYdv4pd/jH6sfLMV2nD0g4gqQekSMmDAAOzevRtLly6FRCLB/Pnz4evri0OHDqFHjx7qyEhEtRBHP4iouqo1T0hdxHlCiKonq6B09GPP1dLRD2cLQ3z1ljdHP4g0gKo/Q5UeCXmmqKgI6enpUCgU5ZY/m8qdiOqfP2PSMXfvdaTKSkc/3mnvglm9OPpBRFWjdAm5e/cuxo0bh/Pnz5dbLggCJBIJ5HK5ysIRUe3wvNGPlW96o60LRz+IqOqULiFjx46FtrY2Dh8+jEaNGtWpKduJSHmn7zzCnN+iykY/xrZ3xuxezTn6QUTVpnQJiYyMRFhYGJo3b66OPERUS2QVFOPLw7ew+2oSAMDJwhBfcfSDiFRI6RLi4eGBjIwMdWQholqCox9EVBOULiErVqzA7NmzsXTpUrRs2RI6Ojrl7ucZJ0R1V3ZBMb78/RZ2Xfl79GPlG63QztVC5GREVB8pfYquVFp6uZl/HwtSVw5M5Sm6RM93LjYDs365hhRZAYC/Rj96N4OhbpVPoiOiekb0U3RPnTpV7RclotqjoFiOFUdvY+u5eACAo7khvnqTox9EpH5Kl5AuXbqoIwcRieBGsgzTdkciNj0HADCynSM+69eCox9EVCMq9U4TFRUFLy8vSKVSREVFvfSxrVq1UkkwIlKfErkCG0/fw+o/7qJEIcDKRA8r32yFV5pZix2NiDRIpUqIj48P0tLSYG1tDR8fH0gkEjzvUJK6cEwIkaaLz8jF9D2RiEh8CgDo42WLLwe3hLmRrrjBiEjjVKqExMXFwcrKquzfRFT3CIKAHZcTseTwLeQXy2Gip41Fr3licOvGnHSQiEQhrcyDnJycyt6knJycXvqlrPXr18PFxQX6+vrw8/NDaGjoSx9fWFiIzz77DE5OTtDT00OTJk3www8/KP26RJokPasA47ZdwWf7biC/WI5AVwscnd4Zr/vas4AQkWiqfPTZzZs3kZiYiKKionLLBw4cWOl17N69G9OmTcP69evRoUMHbNq0CX369MHNmzdfeCG8IUOG4OHDh9iyZQvc3NyQnp6OkpKSqn4bRPXekeup+HTfdTzJK4authSzezXDuA4ukEpZPohIXErPE3L//n0MHjwY169fL3dsyLO/ppQ5JqRdu3bw9fXFhg0bypa1aNECgwYNwrJlyyo8/ujRoxg2bBju378Pc/OqTR3NeUJIU2QVFGPhwWjsDU8GAHg0MsXqYT5oamMicjIiqqtU/Rlaqd0x/zR16lS4uLjg4cOHMDQ0RHR0NM6cOQN/f3/8+eeflV5PUVERwsLC0LNnz3LLe/bsWeEKvc8cPHgQ/v7+WLlyJRo3boymTZvi448/Rn5+/gtfp7CwEFlZWeW+iOq7C/cy0Wd1KPaGJ0MqAT7s2gT7J3VgASGiWkXp3TEXLlzAyZMnYWVlBalUCqlUio4dO2LZsmWYMmUKIiIiKrWejIwMyOVy2NjYlFtuY2ODtLS05z7n/v37OHv2LPT19bFv3z5kZGTgww8/xOPHj194XMiyZcuwaNEi5b5JojqqoFiOr4/FYMu5OAhC6cRjq4Z4w9+ZF50jotpH6ZEQuVwOY2NjAIClpSVSUlIAlB6wGhMTo3SAF03//jwKhQISiQQ///wz2rZti759+2LVqlXYtm3bC0dD5s6dC5lMVvaVlJSkdEaiuiA6RYaBa8/i/86WFpDhbR1wZGonFhAiqrWUHgnx8vJCVFQUXF1d0a5dO6xcuRK6uroICgqCq6trpddjaWkJLS2tCqMe6enpFUZHnmnUqBEaN24MMzOzsmUtWrSAIAh48OAB3N3dKzxHT08Penp6lc5FVNfIFQI2nbmHb0PuoFguwNJYFyveaIVuLZ7/e0REVFsoPRLy+eefQ6FQAACWLFmChIQEdOrUCcHBwfjuu+8qvR5dXV34+fkhJCSk3PKQkBC0b9/+uc/p0KEDUlJSkJOTU7bszp07kEqlsLe3V/ZbIarzEjPzMHTTBaw8GoNiuYBenjY4Nq0zCwgR1QlKnx3zPI8fP0bDhg2Vnm9g9+7dGDVqFDZu3IjAwEAEBQVh8+bNiI6OhpOTE+bOnYvk5GRs374dAJCTk4MWLVogICAAixYtQkZGBt577z106dIFmzdvrtRr8uwYqg8EQcDuK0lYfPgm8orkMNbTxsKBnnjDlxOPEZH6iH4V3eep6umyQ4cORWZmJhYvXozU1FR4eXkhODi4bNKz1NRUJCYmlj3e2NgYISEh+Oijj+Dv7w8LCwsMGTIES5YsUcW3QVQnPMouxNy9UfjjVjoAoK2LOb55yxsO5oYiJyMiUk6lRkJef/31Sq9w79691QqkbhwJobrsWHQaPt17HZm5RdDVkuLjXk3xbkdXaHHiMSKqAaKMhPzzQFAiqnnZBcVYfOgmfgl7AABobmuCb4f6oEUjFmkiqrsqVUK2bt2q7hxE9AKX7mdi5i/X8OBJPiQS4P3OTTC9hzv0tLXEjkZEVC1VPiYkPT0dMTExkEgkaNq0KaytrVWZi0jjFZbIsSrkDoLO3IcgAPYNDbBqiA/aunDeDyKqH5QuIVlZWZg0aRJ27dpVdp0YLS0tDB06FOvWreOuGyIVuJWahem7I3E7LRsAMMTfHvP6e8BEX0fkZEREqqP0PCHvvfceLl26hMOHD+Pp06eQyWQ4fPgwrl69ivHjx6sjI5HGkCsEbDp9D6+tPYfbadmwMNJF0Cg/rHzTmwWEiOodpecJMTIywrFjx9CxY8dyy0NDQ9G7d2/k5uaqNKCq8ewYqq2SHudh5p5ruBz/GADQvYUNlr/REpbGnPGXiGoH0ecJsbCweO4uFzMzMzRs2LDagYg0jSAI2BuejAUHo5FTWAIjXS3MH+CBIf4OnHiMiOq1Kk3bPmPGDKSmppYtS0tLw6xZszBv3jyVhiOq77IKijF1VyRm/nINOYUl8HdqiCNTO2NoG0cWECKq95TeHdO6dWvExsaisLAQjo6OAIDExETo6elVuIBceHi46pKqCHfHUG0RlvAYU3dF4sGTfGhJJZje3R0fdHXjxGNEVGuJvjtm0KBB1X5RIk0mVwhYezIW3528C7lCgIO5AdYMaw1fR+7OJCLNopIL2NUlHAkhMSU/zcf0XZFlB58O8rHDF4O8eOYLEdUJqv4MVfqYkD/++OOF923atKlaYYjqs9+jUtFn9Rlcjn8MYz1tfDvUG6uHtWYBISKNpXQJ6devH2bOnImioqKyZY8ePcKAAQMwd+5clYYjqg9yC0sw+9drmLQjHFkFJfBxaIDfp3TE4Nb2YkcjIhKV0iXkzJkzOHToENq0aYPo6Gj8/vvv8PLyQk5ODq5du6aOjER11vUHMgz4/iz2XH0AiQSY/IobfpkYCCcLI7GjERGJTukDU9u1a4eIiAhMnDgRfn5+UCgUWLJkCWbNmsVTCon+olAI+L+z9/HVsRgUywU0MtPHt0N9EOBqIXY0IqJao0oXsIuJicGVK1dgb2+PlJQU3L59G3l5eTAy4l93ROlZBZix5xrOxmYAAHp72mL5Gy3RwFBX5GRERLWL0rtjli9fjsDAQPTo0QM3btzAlStXEBERgVatWuHChQvqyEhUZ/xx8yF6rwnF2dgM6OtIsez1ltjwti8LCBHRcyg9ErJmzRrs378fffr0AQB4enri8uXL+PTTT9G1a1cUFhaqPCRRbVdQLMfS4FvYfiEBAODRyBTfDW8NN2tjkZMREdVeSpeQ69evw9LSstwyHR0dfPXVV+jfv7/KghHVFbfTsjBlZwTuPMwBALzX0QWzejeDnraWyMmIiGo3pUuIpaUlnj59il9//RX37t3DrFmzYG5ujvDwcLi5uakjI1GtJAgCtl9IwJfBt1BUooClsR6+GeKNLk2txI5GRFQnKF1CoqKi0L17d5iZmSE+Ph7jx4+Hubk59u3bh4SEBGzfvl0dOYlqlcycQsz+NQonbqcDAF5pZoWv3vKGpbGeyMmIiOoOpQ9MnTFjBsaOHYu7d+9CX1+/bHmfPn1w5swZlYYjqo1C7z5C7zWhOHE7HbpaUiwY4IEfxrZhASEiUpLSIyFXrlx57vTsjRs3RlpamkpCEdVGRSUKfH08BkFn7gMA3KyN8f3w1mjRiNcgIiKqCqVLiL6+PrKysiosj4mJgZUV94VT/XT/UQ6m7IrAjeTSn/2R7RzxeT8PGOjy4FMioqpSenfMa6+9hsWLF6O4uBgAIJFIkJiYiDlz5uCNN95QeUAiMQmCgD1XktDvu7O4kZyFBoY62DTKD18ObskCQkRUTRJBEARlnpCVlYW+ffsiOjoa2dnZsLOzQ1paGgIDAxEcHFzrZ01V9WWIqf6S5RXj033X8fv1VABAoKsFvh3qA1sz/f94JhFR/aTqz1Cld8eYmpri7NmzOHnyJMLDw6FQKODr64vu3btXOwxRbXE57jGm7YpAiqwA2lIJZvZshgmdXaEl5fWRiIhURemRkLqOIyH0MiVyBb47cRdrT8VCIQDOFoZYM6w1vB0aiB2NiEh0oo+EENVXSY/zMHVXBMITnwIA3vSzx8KBnjDW468JEZE68N2VCMCByGR8vu8GsgtLYKKnjS9fb4mB3nZixyIiqtdYQkij5RaWYP6BaPwW/gAA4OfUEKuH+sDB3FDkZERE9R9LCGmsmylZmLwzHPcf5UIqAT561R0fveoGbS2lz1wnIqIqqFIJuXfvHrZu3Yp79+5hzZo1sLa2xtGjR+Hg4ABPT09VZyRSKUEQ8NPFBHzxe+mF52xN9bFmmA/auVqIHY2ISKMo/Sff6dOn0bJlS1y6dAl79+5FTk7p5cujoqKwYMEClQckUiVZfjE+/Dkc8w5Eo6hEgVebWyN4aicWECIiEShdQubMmYMlS5YgJCQEurq6ZctfeeUVXLhwQaXhiFQpPPEJ+q4JxZEbadDRkuDzfi2wZYw/zI10//vJRESkckrvjrl+/Tp27NhRYbmVlRUyMzNVEopIlRQKAUGh9/H1sRiUKAQ4mhvi++Gc+4OISGxKl5AGDRogNTUVLi4u5ZZHRESgcePGKgtGpAoZOYWYsecaztx5BADo36oRlr7eEqb6OiInIyIipXfHjBgxAp988gnS0tIgkUigUChw7tw5fPzxxxg9erQ6MhJVyfnYDPRZE4ozdx5BT1uKZa+3xPfDW7OAEBHVEkpP215cXIyxY8di165dEAQB2trakMvlGDFiBLZt2wYtrdp9ZVFO217/PZt6/ftTsRAEwN3aGGtH+KKZrYnY0YiI6jRVf4ZW+dox9+7dQ0REBBQKBVq3bg13d/dqh6kJLCH1W6osH1N3RuJy/GMAwFB/Bywc6AkD3dpdjomI6gLRrx1z+vRpdOnSBU2aNEGTJk2qHYBIVU7ceoiPf7mGJ3nFMNLVwtLXW+I1Hx6nRERUWyldQnr06AFbW1uMGDECb7/9Nry8vNSRi6jSikoUWH7kNn44FwcA8GpsirXDfeFsaSRyMiIiehmlD0xNSUnB7NmzERoailatWqFVq1ZYuXIlHjx4oI58RC+VkJmLNzeeLysg73Rwxm8ftGcBISKqA6p8TAgAxMXFYceOHdi5cydu376Nzp074+TJk6rMp3I8JqT+OHQtBXP3XkdOYQkaGOrgqze90cPDRuxYRET1Vq05MPUZuVyOI0eOYN68eYiKioJcLq92KHViCan78ovkWHw4GjsvJwEA2jg3xJphrWHXwEDkZERE9ZvoB6Y+c+7cOfz888/49ddfUVBQgIEDB2Lp0qXVDkT0MnceZmPyjnDceZgDiQSY/IobpnZz55VviYjqIKVLyKeffoqdO3ciJSUF3bt3x+rVqzFo0CAYGhqqIx8RgNIr3+6+koSFh6JRUKyApbEe1gzzQQc3S7GjERFRFSldQv788098/PHHGDp0KCwt+QFA6pddUIxP993AoWspAIBO7pZYNcQHViZ6IicjIqLqULqEnD9/Xh05iJ7r+gMZJu8MR0JmHrSkEnzcsxne7+wKqVQidjQiIqqmSpWQgwcPok+fPtDR0cHBgwdf+tiBAweqJBhpNkEQ8MO5eCw/cgvFcgGNGxjgu+Gt4efUUOxoRESkIpU6O0YqlSItLQ3W1taQSl98AKBEIuHZMVRtT3KLMOvXa/jjVjoAoJenDVa+4Q0zQ154johITKKcHaNQKJ77byJVuxz3GFN3RSBVVgBdLSk+798CowKcIJFw9wsRUX2j9HmN27dvR2FhYYXlRUVF2L59u0pCkeaRKwR8f+IuhgVdQKqsAK6WRtg3qT1GBzqzgBAR1VNKT1ampaWF1NRUWFtbl1uemZkJa2tr7o4hpaVnFWD6nkici80EALzeujEWD/KCsV6Vp7EhIiI1EH2yMkEQnvuX6YMHD2BmZlbtQKRZztx5hBl7IpGRUwQDHS18McgLb/rZix2LiIhqQKVLSOvWrSGRSCCRSNCtWzdoa//9VLlcjri4OPTu3VvpAOvXr8dXX32F1NRUeHp6YvXq1ejUqdN/Pu/cuXPo0qULvLy8EBkZqfTrkrgUCgHfn4zF6hN3IAhAc1sTrB3hCzdrY7GjERFRDal0CRk0aBAAIDIyEr169YKx8d8fFrq6unB2dsYbb7yh1Ivv3r0b06ZNw/r169GhQwds2rQJffr0wc2bN+Ho6PjC58lkMowePRrdunXDw4cPlXpNEp8srxjTdkfgVMwjAMDwto5YMMAD+jpaIicjIqKapPQxIf/73/8wdOhQ6OvrV/vF27VrB19fX2zYsKFsWYsWLTBo0CAsW7bshc8bNmwY3N3doaWlhf379ys1EsJjQsR1I1mGD34OQ9LjfOhpS7FkkBfe8ncQOxYREVWCqj9DlT47ZsyYMSopIEVFRQgLC0PPnj3LLe/Zs+dLZ2XdunUr7t27hwULFlTqdQoLC5GVlVXui8Txy9UkvLHhPJIe58PB3AB7P2zPAkJEpMGUPjBVLpfj22+/xZ49e5CYmIiioqJy9z9+/LhS68nIyIBcLoeNjU255TY2NkhLS3vuc+7evYs5c+YgNDS03DEpL7Ns2TIsWrSoUo8l9SgskWPhwZvYeTkRAPBqc2t8O8SHk48REWk4pUdCFi1ahFWrVmHIkCGQyWSYMWMGXn/9dUilUixcuFDpAP8+0+ZFZ9/I5XKMGDECixYtQtOmTSu9/rlz50Imk5V9JSUlKZ2Rqi75aT6GbLyAnZcTIZEAM3o0xf+N9mcBISIi5UdCfv75Z2zevBn9+vXDokWLMHz4cDRp0gStWrXCxYsXMWXKlEqtx9LSElpaWhVGPdLT0yuMjgBAdnY2rl69ioiICEyePBlA6eytgiBAW1sbx48fx6uvvlrheXp6etDT49VWxRB69xGm7IzAk7xiNDDUwZphrdGlqZXYsYiIqJZQeiQkLS0NLVu2BAAYGxtDJpMBAPr374/ff/+90uvR1dWFn58fQkJCyi0PCQlB+/btKzze1NQU169fR2RkZNnXxIkT0axZM0RGRqJdu3bKfiukJgqFgHWnYjH6h8t4kleMlo3NcGhyRxYQIiIqR+mREHt7e6SmpsLR0RFubm44fvw4fH19ceXKFaVHHGbMmIFRo0bB398fgYGBCAoKQmJiIiZOnAigdFdKcnIytm/fDqlUCi8vr3LPt7a2hr6+foXlJB5ZfjFm7oksu/jcsDYOWDjQk6ffEhFRBUqXkMGDB+PEiRNo164dpk6diuHDh2PLli1ITEzE9OnTlVrX0KFDkZmZicWLFyM1NRVeXl4IDg6Gk5MTACA1NRWJiYnKRiSR3ErNwsSfwpCQmQddbSm+eM0TQ9u8eL4XIiLSbErPE/JvFy9exPnz5+Hm5oaBAweqKpfacJ4Q9dgb/gCf7ruOgmIFGjcwwMa3/dDSntP4ExHVJ6JfO+bfAgICEBAQUO0gVDcVlSjwxeGb+PFiAgCgS1MrrB7qg4ZGuiInIyKi2q5SJeTgwYOVXmFdGA0h1UiV5eODn8IRmfQUEgkw5VV3TOnmDi1pxVOsiYiI/q1SJeTZdWP+i0QigVwur04eqiPOx2bgo50RyMwtgqm+NtYMa41XmluLHYuIiOqQSpUQhUKh7hxURwiCgI2n7+OrY7ehEACPRqbY+LYfHC0MxY5GRER1TLWPCSHNkVVQjFm/XMOx6NIrF7/pZ48lg7x4+i0REVWJ0iVk8eLFL71//vz5VQ5DtVdMWjYm/hSGuIxc6GpJsXCgJ4a3dXjuFPtERESVoXQJ2bdvX7nbxcXFiIuLg7a2Npo0acISUg8diEzGnN+uI79YDjszfWx42w/eDg3EjkVERHWc0iUkIiKiwrKsrCyMHTsWgwcPVkkoqh2KShRYGnwL287HAwA6uVtizbDWMOfpt0REpALVnqzsmRs3bqB///6Ij49XxerUhpOVVU6arACTdoQjLOEJAGDyK26Y3qMpT78lItJgtW6ysmeePn1adjE7qtsu3MvERzvDkZFTBBN9bXw7xAfdPSpe2ZiIiKg6lC4h3333XbnbgiAgNTUVP/74I3r37q2yYFTzBEHA5tD7WHE0BnKFgOa2Jtj4th+cLY3EjkZERPWQ0iXk22+/LXdbKpXCysoKY8aMwdy5c1UWjGpWTmEJZv1yDUdupAEAXm/dGF8ObgkDXZ5+S0RE6qF0CYmLi1NHDhLR3YfZeP+nMNx/lAsdLQnmD/DE2+0cefotERGpFScr03CHo1Iw+9co5BXJ0chMH+tG+sLXsaHYsYiISAMoXUIKCgrw/fff49SpU0hPT68wpXt4eLjKwpH6FMsVWH7kNracLR3Zat/EAt8Nbw1LYz2RkxERkaZQuoSMGzcOISEhePPNN9G2bVsO2ddBj3OLMOnncFy4nwkA+KBrE8zs0RTaWlKRkxERkSZRuoT8/vvvCA4ORocOHdSRh9QsOkWGCdvDkPw0H0a6WvhmiA96e9mKHYuIiDSQ0iWkcePGMDExUUcWUrOD11Iw+9drKChWwNnCEEGj/dHUhv+XREQkDqXH37/55ht88sknSEhIUEceUgO5QsCyI7cwZWcECooV6NLUCgcmdWQBISIiUSk9EuLv74+CggK4urrC0NAQOjo65e5//PixysJR9cnyivHRrgicufMIADCxSxPM6tWM068TEZHolC4hw4cPR3JyMpYuXQobGxsemFqL3XmYjfHbryIhMw/6OlJ89aY3BnjbiR2LiIgIQBVKyPnz53HhwgV4e3urIw+pyNEbaZi5JxK5RXI0bmCAzaP94WHHC/YREVHtoXQJad68OfLz89WRhVRAoRCw+sRdfHfiLgAg0NUC60b6wtxIV+RkRERE5Sl9YOry5csxc+ZM/Pnnn8jMzERWVla5LxJPdkExJvx4tayAjOvggh/fbcsCQkREtZJEEARBmSdIpaW95d/HggiCAIlEArlcrrp0apCVlQUzMzPIZDKYmtaf3RP3H+Vg/ParuPcoF7raUiwb3BJv+NmLHYuIiOoRVX+GKr075tSpU9V+UVKtk7cfYurOSGQXlsDWVB+bRvnB26GB2LGIiIheSukS0qVLF3XkoCoQBAHr/7yHr4/HQBCANs4NsX6kH6xMeP0XIiKq/ZQuIWfOnHnp/Z07d65yGKq83MISzPr1GoKvpwEARrZzxIIBntDV5vVfiIioblC6hHTt2rXCsn8eH1LbjwmpDxIz8zDhx6u4nZYNHS0JFg30woh2jmLHIiIiUorSJeTJkyflbhcXFyMiIgLz5s3Dl19+qbJg9Hxn72Zg0o5wyPKLYWWih41v+8LPyVzsWEREREpTuoSYmZlVWNajRw/o6elh+vTpCAsLU0kwKk8QBGw5G4elwbegEABvhwbY9LYfbM30xY5GRERUJUqXkBexsrJCTEyMqlZH/1BQLMec36KwPzIFAPCmnz2WDPKCvo6WyMmIiIiqTukSEhUVVe62IAhITU3F8uXLOZW7GiQ/zcf7P17FjeQsaEklmN/fA6MDnXjNHiIiqvOULiE+Pj6QSCT49xxnAQEB+OGHH1QWjIBL9zPx4c/hyMwtgrmRLtaN8EVgEwuxYxEREamE0iUkLi6u3G2pVAorKyvo6/PYBFURBAE/XkzA4kM3UaIQ4Glnik2j/GDf0FDsaERERCqjdAlxcnJSRw76S2GJHPP238Ceqw8AAAO97bDijVYw0OXxH0REVL9UemarkydPwsPD47kXqZPJZPD09ERoaKhKw2mah1kFGBZ0EXuuPoBUAnzatznWDPNhASEionqp0iVk9erVGD9+/HMvWGNmZob3338fq1atUmk4TRKW8AT9vz+LiMSnMDPQwbZ32mJC5yY8AJWIiOqtSpeQa9euoXfv3i+8v2fPnpwjpIp2X0nE8KCLeJRdiGY2Jjg4uQM6N7USOxYREZFaVfqYkIcPH0JHR+fFK9LWxqNHj1QSSlMUlSjwxeGb+PFiAgCgt6ctvhniDSM9lU3fQkREVGtV+tOucePGuH79Otzc3J57f1RUFBo1aqSyYPVdRk4hPvwpHJfjH0MiAWZ0b4pJr7hBKuXuFyIi0gyV3h3Tt29fzJ8/HwUFBRXuy8/Px4IFC9C/f3+VhquvYtKyMeD7s7gc/xgmetrYPMofH3VzZwEhIiKNIhH+PevYCzx8+BC+vr7Q0tLC5MmT0axZM0gkEty6dQvr1q2DXC5HeHg4bGxs1J25WrKysmBmZgaZTPbcg2zV7c7DbAwPuojM3CK4WhkhaJQ/3KyNazwHERGRslT9GVrp3TE2NjY4f/48PvjgA8ydO7dsxlSJRIJevXph/fr1tb6AiO3uw2yM2FxaQDztTPHze+3QwFBX7FhERESiUOoISCcnJwQHB+PJkyeIjY2FIAhwd3dHw4YN1ZWv3ohNz8bwzZeQkVMEj0YsIERERFU6DaNhw4Zo06aNqrPUW7HpORgWdAkZOYVowQJCREQEQIkDU6lq7j3KwfDNF5GRU4jmtib4+b12aGjEAkJERMQSokb3H+WUTULW3NYEO8YHwJwFhIiICABLiNrEZeRi+OaLSP9rFtSf32vHAkJERPQPLCFqEJ+Ri+FBF/EwqxBNbYzx8/h2sDDWEzsWERFRrcISomIJmaUjIGlZBXC3NsaO8QGwZAEhIiKqgCVEhRIyczEs6CJSZQVwYwEhIiJ6KZYQFUnMzMPwvwpIEysj7BjfDlYmLCBEREQvwhKiAkmP8zB880WkyArgamWEneMDYG2iL3YsIiKiWk30ErJ+/Xq4uLhAX18ffn5+CA0NfeFj9+7dix49esDKygqmpqYIDAzEsWPHajBtRUmP8zAs6CKSn+bD1dIIu8YHwNqUBYSIiOi/iFpCdu/ejWnTpuGzzz5DREQEOnXqhD59+iAxMfG5jz9z5gx69OiB4OBghIWF4ZVXXsGAAQMQERFRw8lLPXhSOgKS/DQfLpZG2DmBBYSIiKiyKn0VXXVo164dfH19sWHDhrJlLVq0wKBBg7Bs2bJKrcPT0xNDhw7F/PnzK/V4VV0BMPlpPoYFXUDS43w4Wxhi14RA2JqxgBARUf2l6qvoijYSUlRUhLCwMPTs2bPc8p49e+L8+fOVWodCoUB2djbMzc3VEfGFUp7mY3jQRSQ9zoeThSF2TghgASEiIlJSlS5gpwoZGRmQy+WwsbEpt9zGxgZpaWmVWsc333yD3NxcDBky5IWPKSwsRGFhYdntrKysqgX+S6osH8M3X0Ti4zw4mhti5/gANDIzqNY6iYiINJHoB6ZKJJJytwVBqLDseXbu3ImFCxdi9+7dsLa2fuHjli1bBjMzs7IvBweHKmdNkxVgeNBFJGTmwcHcADsnBMCuAQsIERFRVYhWQiwtLaGlpVVh1CM9Pb3C6Mi/7d69G++++y727NmD7t27v/Sxc+fOhUwmK/tKSkqqUt40WQGGb76I+L8KyK4JgWjMAkJERFRlopUQXV1d+Pn5ISQkpNzykJAQtG/f/oXP27lzJ8aOHYsdO3agX79+//k6enp6MDU1LfelrIdZBRix+SLiMnJh39AAO8cHsIAQERFVk2jHhADAjBkzMGrUKPj7+yMwMBBBQUFITEzExIkTAZSOYiQnJ2P79u0ASgvI6NGjsWbNGgQEBJSNohgYGMDMzEwtGdOzSkdA7mfkonGD0gJi39BQLa9FRESkSUQtIUOHDkVmZiYWL16M1NRUeHl5ITg4GE5OTgCA1NTUcnOGbNq0CSUlJZg0aRImTZpUtnzMmDHYtm2byvOlZ/9VQB6VFpBdEwLgYM4CQkREpAqizhMihsqe4/wouxDDN19EbHoO7Mz0sWtCIBwtWECIiEhz1Zt5QmqzR9mFGPFXAWlkpo+dEwJYQIiIiFSMJeRfMnIKMfL/LuJueg5sTfWxc3wAnCyMxI5FRERU77CE/ENmTiFGbr6EOw9zYGOqh50TAuBsyQJCRESkDiwhf8nMKcTI/7uEmIfZsDbRw64JgXBhASEiIlIblhAAj3OLMPL/LuF2WmkB2TkhgAWEiIhIzTS+hDz5RwGxMtHDjvEBaGJlLHYsIiKiek+jS8jTvNICcis1C5bGetg5PgBu1iwgRERENUHUycrE9DSvCB/suYabqVmwNNbFrgntWECIiIhqkMaWkPHbryLmsRwWRrp/jYCYiB2JiIhIo2js7phbqdmwMNLFjvEBcLdhASEiIqppGltCGhrqYMf4ADSzZQEhIiISg8aWkC1j/VlAiIiIRKSxJaSpTfUvvENERERVp7ElhIiIiMTFEkJERESiYAkhIiIiUbCEEBERkShYQoiIiEgULCFEREQkCpYQIiIiEgVLCBEREYmCJYSIiIhEwRJCREREomAJISIiIlFoix2gpgmCAADIysoSOQkREVHd8uyz89lnaXVpXAnJzMwEADg4OIichIiIqG7KzMyEmZlZtdejcSXE3NwcAJCYmKiSDViXZWVlwcHBAUlJSTA11dyrCnM7/I3bohS3w9+4LUpxO5SSyWRwdHQs+yytLo0rIVJp6WEwZmZmGv2D9E+mpqbcFuB2+Cdui1LcDn/jtijF7VDq2WdptdejkrUQERERKYklhIiIiEShcSVET08PCxYsgJ6enthRRMdtUYrb4W/cFqW4Hf7GbVGK26GUqreDRFDVeTZEREREStC4kRAiIiKqHVhCiIiISBQsIURERCQKlhAiIiIShcaVkPXr18PFxQX6+vrw8/NDaGio2JFq1LJly9CmTRuYmJjA2toagwYNQkxMjNixaoVly5ZBIpFg2rRpYkepccnJyXj77bdhYWEBQ0ND+Pj4ICwsTOxYNa6kpASff/45XFxcYGBgAFdXVyxevBgKhULsaGp15swZDBgwAHZ2dpBIJNi/f3+5+wVBwMKFC2FnZwcDAwN07doV0dHR4oRVs5dti+LiYnzyySdo2bIljIyMYGdnh9GjRyMlJUW8wGryXz8T//T+++9DIpFg9erVSr+ORpWQ3bt3Y9q0afjss88QERGBTp06oU+fPkhMTBQ7Wo05ffo0Jk2ahIsXLyIkJAQlJSXo2bMncnNzxY4mqitXriAoKAitWrUSO0qNe/LkCTp06AAdHR0cOXIEN2/exDfffIMGDRqIHa3GrVixAhs3bsTatWtx69YtrFy5El999RW+//57saOpVW5uLry9vbF27drn3r9y5UqsWrUKa9euxZUrV2Bra4sePXogOzu7hpOq38u2RV5eHsLDwzFv3jyEh4dj7969uHPnDgYOHChCUvX6r5+JZ/bv349Lly7Bzs6uai8kaJC2bdsKEydOLLesefPmwpw5c0RKJL709HQBgHD69Gmxo4gmOztbcHd3F0JCQoQuXboIU6dOFTtSjfrkk0+Ejh07ih2jVujXr58wbty4cstef/114e233xYpUc0DIOzbt6/stkKhEGxtbYXly5eXLSsoKBDMzMyEjRs3ipCw5vx7WzzP5cuXBQBCQkJCzYQSwYu2w4MHD4TGjRsLN27cEJycnIRvv/1W6XVrzEhIUVERwsLC0LNnz3LLe/bsifPnz4uUSnwymQwAVHYxorpo0qRJ6NevH7p37y52FFEcPHgQ/v7+eOutt2BtbY3WrVtj8+bNYscSRceOHXHixAncuXMHAHDt2jWcPXsWffv2FTmZeOLi4pCWllbuvVNPTw9dunTR6PfOZ2QyGSQSicaNHCoUCowaNQqzZs2Cp6dnldejMRewy8jIgFwuh42NTbnlNjY2SEtLEymVuARBwIwZM9CxY0d4eXmJHUcUu3btQnh4OK5cuSJ2FNHcv38fGzZswIwZM/Dpp5/i8uXLmDJlCvT09DB69Gix49WoTz75BDKZDM2bN4eWlhbkcjm+/PJLDB8+XOxoonn2/vi8986EhAQxItUaBQUFmDNnDkaMGKFxF7VbsWIFtLW1MWXKlGqtR2NKyDMSiaTcbUEQKizTFJMnT0ZUVBTOnj0rdhRRJCUlYerUqTh+/Dj09fXFjiMahUIBf39/LF26FADQunVrREdHY8OGDRpXQnbv3o2ffvoJO3bsgKenJyIjIzFt2jTY2dlhzJgxYscTFd87yysuLsawYcOgUCiwfv16sePUqLCwMKxZswbh4eHV/hnQmN0xlpaW0NLSqjDqkZ6eXqHha4KPPvoIBw8exKlTp2Bvby92HFGEhYUhPT0dfn5+0NbWhra2Nk6fPo3vvvsO2trakMvlYkesEY0aNYKHh0e5ZS1atNCoA7afmTVrFubMmYNhw4ahZcuWGDVqFKZPn45ly5aJHU00tra2AMD3zn8oLi7GkCFDEBcXh5CQEI0bBQkNDUV6ejocHR3L3jsTEhIwc+ZMODs7K7UujSkhurq68PPzQ0hISLnlISEhaN++vUipap4gCJg8eTL27t2LkydPwsXFRexIounWrRuuX7+OyMjIsi9/f3+MHDkSkZGR0NLSEjtijejQoUOF07Tv3LkDJycnkRKJJy8vD1Jp+bdFLS2ten+K7su4uLjA1ta23HtnUVERTp8+rVHvnc88KyB3797FH3/8AQsLC7Ej1bhRo0YhKiqq3HunnZ0dZs2ahWPHjim1Lo3aHTNjxgyMGjUK/v7+CAwMRFBQEBITEzFx4kSxo9WYSZMmYceOHThw4ABMTEzK/roxMzODgYGByOlqlomJSYVjYYyMjGBhYaFRx8hMnz4d7du3x9KlSzFkyBBcvnwZQUFBCAoKEjtajRswYAC+/PJLODo6wtPTExEREVi1ahXGjRsndjS1ysnJQWxsbNntuLg4REZGwtzcHI6Ojpg2bRqWLl0Kd3d3uLu7Y+nSpTA0NMSIESNETK0eL9sWdnZ2ePPNNxEeHo7Dhw9DLpeXvYeam5tDV1dXrNgq918/E/8uXzo6OrC1tUWzZs2Ue6HqnbhT96xbt05wcnISdHV1BV9fX407NRXAc7+2bt0qdrRaQRNP0RUEQTh06JDg5eUl6OnpCc2bNxeCgoLEjiSKrKwsYerUqYKjo6Ogr68vuLq6Cp999plQWFgodjS1OnXq1HPfF8aMGSMIQulpugsWLBBsbW0FPT09oXPnzsL169fFDa0mL9sWcXFxL3wPPXXqlNjRVeq/fib+raqn6EoEQRCUqy1ERERE1acxx4QQERFR7cISQkRERKJgCSEiIiJRsIQQERGRKFhCiIiISBQsIURERCQKlhAiIiISBUsIUT0THx8PiUSCyMhIsaOUuX37NgICAqCvrw8fHx+x4xBRLcESQqRiY8eOhUQiwfLly8st379/v8ZedXTBggUwMjJCTEwMTpw4IXacOqtr166YNm2a2DGIVIYlhEgN9PX1sWLFCjx58kTsKCpTVFRU5efeu3cPHTt2hJOTk0Ze8IuIno8lhEgNunfvDltb25deAn7hwoUVdk2sXr263KWwx44di0GDBmHp0qWwsbFBgwYNsGjRIpSUlGDWrFkwNzeHvb09fvjhhwrrv337Ntq3bw99fX14enrizz//LHf/zZs30bdvXxgbG8PGxgajRo1CRkZG2f1du3bF5MmTMWPGDFhaWqJHjx7P/T4UCgUWL14Me3t76OnpwcfHB0ePHi27XyKRICwsDIsXL4ZEIsHChQtfuJ4VK1bAzc0Nenp6cHR0xJdffll2//Xr1/Hqq6/CwMAAFhYWmDBhAnJycqq1rZ7tutq1a9dLt9Xp06fRtm1b6OnpoVGjRpgzZw5KSkrKbaspU6Zg9uzZMDc3h62tbYXvUyaTYcKECbC2toapqSleffVVXLt2rez+Zz8PP/74I5ydnWFmZoZhw4YhOzu77Ps7ffo01qxZA4lEAolEgvj4eDx58gQjR46ElZUVDAwM4O7ujq1btz53GxPVNiwhRGqgpaWFpUuX4vvvv8eDBw+qta6TJ08iJSUFZ86cwapVq7Bw4UL0798fDRs2xKVLlzBx4kRMnDgRSUlJ5Z43a9YszJw5ExEREWjfvj0GDhyIzMxMAEBqaiq6dOkCHx8fXL16FUePHsXDhw8xZMiQcuv43//+B21tbZw7dw6bNm16br41a9bgm2++wddff42oqCj06tULAwcOxN27d8tey9PTEzNnzkRqaio+/vjj565n7ty5WLFiBebNm4ebN29ix44dsLGxAQDk5eWhd+/eaNiwIa5cuYJffvkFf/zxByZPnqz2bZWcnIy+ffuiTZs2uHbtGjZs2IAtW7ZgyZIlFbaVkZERLl26hJUrV2Lx4sUICQkBAAiCgH79+iEtLQ3BwcEICwuDr68vunXrhsePH5et4969e9i/fz8OHz6Mw4cP4/Tp02W79dasWYPAwECMHz8eqampSE1NhYODQ9n2OnLkCG7duoUNGzbA0tLyuduYqNapxkX2iOg5xowZI7z22muCIAhCQECAMG7cOEEQBGHfvn3CP3/lFixYIHh7e5d77rfffis4OTmVW5eTk5Mgl8vLljVr1kzo1KlT2e2SkhLByMhI2LlzpyAIQtmVPpcvX172mOLiYsHe3l5YsWKFIAiCMG/ePKFnz57lXjspKUkAIMTExAiCUHpFYR8fn//8fu3s7IQvv/yy3LI2bdoIH374Ydltb29vYcGCBS9cR1ZWlqCnpyds3rz5ufcHBQUJDRs2FHJycsqW/f7774JUKhXS0tIEQVDftvr000+FZs2aCQqFouwx69atE4yNjcteq0uXLkLHjh0rbINPPvlEEARBOHHihGBqaioUFBSUe0yTJk2ETZs2CYJQ+vNgaGgoZGVlld0/a9YsoV27dmW3n3eV5wEDBgjvvPPOc7cbUW3HkRAiNVqxYgX+97//4ebNm1Veh6enJ6TSv39VbWxs0LJly7LbWlpasLCwQHp6ernnBQYGlv1bW1sb/v7+uHXrFgAgLCwMp06dgrGxcdlX8+bNAZT+Nf6Mv7//S7NlZWUhJSUFHTp0KLe8Q4cOZa9VGbdu3UJhYSG6dev2wvu9vb1hZGRU7jUUCgViYmLKlqljW926dQuBgYHlDiru0KEDcnJyyo1ytWrVqtw6GzVqVPY6YWFhyMnJgYWFRbltHhcXV257Ozs7w8TE5LnreJEPPvgAu3btgo+PD2bPno3z58+/9PFEtYm22AGI6rPOnTujV69e+PTTTzF27Nhy90mlUgiCUG5ZcXFxhXXo6OiUuy2RSJ67TKFQ/GeeZx+kCoUCAwYMwIoVKyo8plGjRmX//ueHfmXW+4wgCEqdCWRgYPDS+1+2vn8uV8e2et5rP/t/+6/XfvY6CoUCjRo1qnCsCQA0aNCgUut4kT59+iAhIQG///47/vjjD3Tr1g2TJk3C119//fJvkKgW4EgIkZotX74chw4dqvAXqpWVFdLS0soVEVXO7XHx4sWyf5eUlCAsLKxstMPX1xfR0dFwdnaGm5tbua/KFg8AMDU1hZ2dHc6ePVtu+fnz59GiRYtKr8fd3R0GBgYvPH3Xw8MDkZGRyM3NLVt27tw5SKVSNG3atNKv8yIv21YeHh44f/58uf+n8+fPw8TEBI0bN67U+n19fZGWlgZtbe0K21uZ4zd0dXUhl8srLLeyssLYsWPx008/YfXq1QgKCqr0OonExBJCpGYtW7bEyJEj8f3335db3rVrVzx69AgrV67EvXv3sG7dOhw5ckRlr7tu3Trs27cPt2/fxqRJk/DkyROMGzcOADBp0iQ8fvwYw4cPx+XLl3H//n0cP34c48aNe+6H3MvMmjULK1aswO7duxETE4M5c+YgMjISU6dOrfQ69PX18cknn2D27NnYvn077t27h4sXL2LLli0AgJEjR0JfXx9jxozBjRs3cOrUKXz00UcYNWpU2cGr1fGybfXhhx8iKSkJH330EW7fvo0DBw5gwYIFmDFjRrldPy/TvXt3BAYGYtCgQTh27Bji4+Nx/vx5fP7557h69Wqlczo7O+PSpUuIj49HRkYGFAoF5s+fjwMHDiA2NhbR0dE4fPiwUgWQSEwsIUQ14Isvvqiw66VFixZYv3491q1bB29vb1y+fPmFZ45UxfLly7FixQp4e3sjNDQUBw4cKPur287ODufOnYNcLkevXr3g5eWFqVOnwszMrNIfrM9MmTIFM2fOxMyZM9GyZUscPXoUBw8ehLu7u1LrmTdvHmbOnIn58+ejRYsWGDp0aNnxEIaGhjh27BgeP36MNm3a4M0330S3bt2wdu1apV7jRV62rRo3bozg4GBcvnwZ3t7emDhxIt599118/vnnlV6/RCJBcHAwOnfujHHjxqFp06YYNmwY4uPjlSpRH3/8MbS0tODh4QErKyskJiZCV1cXc+fORatWrdC5c2doaWlh165dSm8DIjFIhH+/MxIRaYj4+Hi4uLggIiKC08kTiYAjIURERCQKlhAiIiISBXfHEBERkSg4EkJERESiYAkhIiIiUbCEEBERkShYQoiIiEgULCFEREQkCpYQIiIiEgVLCBEREYmCJYSIiIhEwRJCREREovh/yjPmSyccOqAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlim(0, 14)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aa75dd-1a81-4455-9f26-4840c2ca7005",
   "metadata": {},
   "source": [
    "### Comment\n",
    "The above plot shows that almost 90% of variance is explained by the first 12 components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e931a088-6004-49b2-b50a-5a2ecda28d84",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "-\tIn this kernel, I have discussed Principal Component Analysis – the most popular dimensionality reduction technique.\n",
    "-\tI have demonstrated PCA implementation with Logistic Regression on the adult dataset.\n",
    "-\tI found the maximum accuracy with the first 12 features and it is found to be 0.8227.\n",
    "-\tAs expected, the number of dimensions required to preserve 90 % of variance is found to be 12.\n",
    "-\tFinally, I plot the explained variance ratio with number of dimensions. The graph confirms that approximately 90% of variance is explained by the first 12 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d450f3-6448-4117-a749-30a0a5ae571c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
